{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training and testing data should be POS tagged (e.g., mystem for Russian) and saved as word POS word POS ...\n",
    "# as implemented in notebook rule_based_classification.ipynb\n",
    "\n",
    "# input files:\n",
    "# CNN predictions in form of probabilities as .txt file: probability\\tquestion, where probability - a prob. that a question is comp.\n",
    "# BERT predictions in form of probabilities as .txt file: probability1\\t\\tprobaility2\\tquestion, where probability1 is a prob. that a question is not comp., probability2 - otherwise\n",
    "# ML (SVM and log. regr) predictions as .txt file: svm_probabilities\\tlr_probabilities\\tquestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "### Helper functions to read probabilities\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def read_cnn_questions_probabilities():\n",
    "    cnn_questions=[]\n",
    "    cnn_probabilities=[]\n",
    "    for n in range(10): # adjusted to 10-Fold Crossvalidation producing a separ. file for each split\n",
    "        path_cnn = 'path_to_CNN_predictions'\n",
    "        filename = glob.glob(os.path.join(path_cnn, 'file' + str(n) + '.txt')) # change to your file names  \n",
    "        with open(filename[0]) as f:\n",
    "            content = f.readlines()\n",
    "        cnn_probabilities += [float(x.strip('\\n').split('\\t')[0]) for x in content[1:]] # ignore heading in the input file\n",
    "        cnn_questions += [x.strip('\\n').split('\\t')[1] for x in content[1:]] # ignore heading in the input file\n",
    "    return  cnn_probabilities, cnn_questions \n",
    "\n",
    "def read_bert_questions_probabilities():\n",
    "    bert_questions=[]\n",
    "    bert_probabilities=[]\n",
    "    for n in range(10):\n",
    "        path_bert = 'path_to_BERT_predictions'  \n",
    "        filename = glob.glob(os.path.join(path_bert, 'file' + str(n) + '.txt'))\n",
    "        with open(filename[0]) as f:\n",
    "            content = f.readlines()\n",
    "        bert_probabilities += [float(x.strip('\\n').split('\\t')[1]) for x in content] # no heading in the input file\n",
    "        bert_questions += [x.strip('\\n').split('\\t')[2] for x in content] # no heading in the input file\n",
    "    return bert_probabilities, bert_questions\n",
    "\n",
    "def read_ml_questions_probabilities():\n",
    "    ml_questions=[]\n",
    "    svm_probabilities=[]\n",
    "    lr_probabilities=[]\n",
    "    for n in range(10):\n",
    "        path_ml = 'path_to_ML_predictions'\n",
    "        filename = glob.glob(os.path.join(path_ml, 'file' + str(n) + '.txt'))\n",
    "        with open(filename[0]) as f:\n",
    "            content = f.readlines()\n",
    "        svm_probabilities += [float(x.strip('\\n').split('\\t')[0]) for x in content[1:]] # ignore heading in the input file\n",
    "        lr_probabilities += [float(x.strip('\\n').split('\\t')[1]) for x in content[1:]] # ignore heading in the input file\n",
    "        ml_questions += [x.strip('\\n').split('\\t')[2]for x in content[1:]]\n",
    "    return  svm_probabilities, lr_probabilities, ml_questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Ensemble classifier on a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading probabilities in a dataframe\n",
    "\n",
    "cnn_probabilities, cnn_questions = read_cnn_questions_probabilities()\n",
    "bert_probabilities, bert_questions = read_bert_questions_probabilities()\n",
    "svm_probabilities, lr_probabilities, ml_questions = read_ml_questions_probabilities()\n",
    "#neural_predictions = list(zip(cnn_probabilities, bert_probabilities, svm_probabilities, lr_probabilities, bert_questions, cnn_questions, ml_questions))\n",
    "neural_predictions_df = pd.DataFrame({'cnn_probabilities':cnn_probabilities, 'bert_probabilities':bert_probabilities, \n",
    "                                      'svm_probabilities':svm_probabilities, 'lr_probabilities':lr_probabilities, \n",
    "                                      'bert_questions':bert_questions, 'cnn_questions':cnn_questions, 'ml_questions':ml_questions})\n",
    "\n",
    "# all_predictions_df contains probabilities of all classifiers along with questions\n",
    "# Columns: 'cnn_probabilities', 'bert_probabilities', 'svm_probabilities', 'lr_probabilities', 'bert_questions', 'cnn_questions', 'ml_questions'\n",
    "\n",
    "global all_predictions_df\n",
    "all_predictions_df = neural_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read data from train split\n",
    "\n",
    "dataset = 'train-binary.txt'\n",
    "data = pd.read_csv(join('path_to_train_data', dataset), sep='\\t')\n",
    "\n",
    "questions_original = np.array([question for question in data['question'].tolist()]) # questions before POS tagging\n",
    "questions = np.array([pos(mst.process(strip_punct(question))) for question in data['question'].tolist()]) # produce POS tagging on a fly\n",
    "# see notebook rule_based_classification.ipynb for example with mystem in Russian\n",
    "# or ignore if training data was already POS tagged\n",
    "labels = np.array(data.comp.tolist())\n",
    "\n",
    "dataset = 'train-binary-afterpb.txt' # dataset produced after removing questions classified with rules (see notebook rule_based_classification.ipynb)\n",
    "# which produce predicitons with precision 1. In our case, the first 7 rules from the notebook\n",
    "\n",
    "data_afterpb_df = pd.read_csv(join('path_to_train_data', dataset), sep='\\t')\n",
    "\n",
    "questions_afterpb = np.array([pos(mst.process(strip_punct(question))) for question in data_afterpb_df['question'].tolist()]) # produce POS tagging on a fly\n",
    "# or ignore if training data was already POS tagged\n",
    "\n",
    "labels_afterpb = np.array(data_afterpb_df.comp.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions based on the ML probabilities combined with rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# We add the 8th rule (in Russian) which recalls extra 20% but makes precision not 1 any more.\n",
    "# We will then fix FP using ML\n",
    "\n",
    "def predict_pattern(question):\n",
    "    if (re.search('луч.{0,1}ше ', question) and not re.search('как ', question)): prediction = 1\n",
    "    elif (re.search('comp', question) and re.search(' или | vs | vs.', question) and question.find('comp') < question.find(' или ') and not re.search('более comp или conj менее comp', question)): prediction = 1\n",
    "    elif (re.search('как', question) and re.search('правильно', question) and re.search(' или ', question)) or (re.search('как', question) and re.search('пишется | писать | написать', question) and re.search(' или ', question)): prediction = 1\n",
    "    elif (re.search('что ', question) and re.search(r'общего | сходст| схож', question) and re.search(' и | от | или | между | vs | vs. | versus ', question)): prediction = 1\n",
    "    elif (re.search('выб+рать|купить|взять', question) and re.search(r' или | между | vs | vs. | versus ', question)): prediction = 1\n",
    "    elif ((re.search(' в ', question)) and re.search(' сравнении ', question)) or ((re.search(' по ', question)) and re.search(' сравнению ', question)): prediction = 1\n",
    "    elif (re.search('преимуществ|недостаток', question) and re.search('перед | над | сравнен | vs | vs. | versus', question)): prediction = 1\n",
    "    elif (re.search(' отлич| разница | различие | различ', question) and re.search(' и | от | или | между | vs | vs. | versus', question) and not re.search('что ', question)): prediction = 1\n",
    "    else: prediction = 0\n",
    "    return prediction\n",
    "\n",
    "def binary_pred(prob, thre=0.5):\n",
    "    if prob >= thre: pred = 1\n",
    "    else: pred = 0\n",
    "    return pred\n",
    "\n",
    "def precision_recall(probabilities):\n",
    "    comb_predictions = []\n",
    "    thresholds = []\n",
    "\n",
    "    for pr_pos in np.arange(0.0, 0.99, 0.001): # manipulate the step of the probability threshold in order to draw precision-recall curve\n",
    "        comb_predictions_ = []\n",
    "        pr_pos = round(pr_pos,5)\n",
    "        for item in probabilities:\n",
    "            pred = binary_pred(item, thre=pr_pos)\n",
    "            comb_predictions_.append(pred)\n",
    "        comb_predictions_ = np.pad(comb_predictions_, (0,476), 'constant', constant_values=1) # predictions would be padded with ones for those predicted by the rules as 1\n",
    "        comb_predictions.append(comb_predictions_)\n",
    "        thresholds.append(pr_pos)\n",
    "    predictions_thresholds = list(zip(comb_predictions, thresholds))\n",
    "    dicts_low = {}\n",
    "    keys = [str(item[1]) for item in predictions_thresholds]\n",
    "    for i in range(len(keys)):\n",
    "            dicts_low[keys[i]] = predictions_thresholds[i][0]\n",
    "            \n",
    "    comb_predictions = []\n",
    "    thresholds = []\n",
    "\n",
    "    for pr_pos in np.arange(0.99, 1.00001, 0.00001): # the high probabilities are very senstitive to the step in making decision so that we reduces the step \n",
    "        comb_predictions_ = []\n",
    "        pr_pos = round(pr_pos,5)\n",
    "        for item in probabilities:\n",
    "            pred = binary_pred(item, thre=pr_pos)\n",
    "            comb_predictions_.append(pred)\n",
    "        comb_predictions_ = np.pad(comb_predictions_, (0,476), 'constant', constant_values=1)\n",
    "        comb_predictions.append(comb_predictions_)\n",
    "        thresholds.append(pr_pos)\n",
    "    predictions_thresholds = list(zip(comb_predictions, thresholds))\n",
    "    dicts_hi = {}\n",
    "    keys = [str(item[1]) for item in predictions_thresholds]\n",
    "    for i in range(len(keys)):\n",
    "            dicts_hi[keys[i]] = predictions_thresholds[i][0]\n",
    "    \n",
    "    dicts={}\n",
    "    dicts = {**dicts_low, **dicts_hi}\n",
    "\n",
    "    labels_afterpb_padded = np.pad(labels_afterpb, (0,476), 'constant', constant_values=1)\n",
    "    recall = []\n",
    "    precision = []\n",
    "    thresholds = []\n",
    "    for keys, values in dicts.items():\n",
    "        precision_ = classification_report(y_true=labels_afterpb_padded, y_pred=values, output_dict=True)['1']['precision']\n",
    "        recall_ = classification_report(y_true=labels_afterpb_padded, y_pred=values, output_dict=True)['1']['recall']\n",
    "        precision.append(round(precision_, 3))\n",
    "        recall.append(round(recall_,3))\n",
    "        thresholds.append(keys)\n",
    "    return precision, recall, thresholds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
